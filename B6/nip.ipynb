{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c51f27",
   "metadata": {},
   "source": [
    "- NLP NATURAL LANGUAGE PROGRESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b26baf9",
   "metadata": {},
   "source": [
    "# import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6493a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff25cd",
   "metadata": {},
   "source": [
    "# add data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "188de787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tôi thích học khoá Computer Science.', 'Bạn có đam mê khoa học máy tính không?', 'Huy thích lập trình giải quyết vấn đề.', 'An muốn lập trình game bằng Python.', 'Mỹ có nhiều dự án Scratch hay.', 'Em thấy lập trình giống với trò chơi giải đố.', 'Không có gì đã bằng code chạy lần đầu tiên đúng luôn', 'Sở thích của mình là lập trình các dự án hay']\n"
     ]
    }
   ],
   "source": [
    "# Dữ liệu mẫu\n",
    "sentences = [\n",
    "    \"Tôi thích học khoá Computer Science.\",\n",
    "    \"Bạn có đam mê khoa học máy tính không?\",\n",
    "    \"Huy thích lập trình giải quyết vấn đề.\",\n",
    "    \"An muốn lập trình game bằng Python.\",\n",
    "    \"Mỹ có nhiều dự án Scratch hay.\",\n",
    "    \"Em thấy lập trình giống với trò chơi giải đố.\",\n",
    "    \"Không có gì đã bằng code chạy lần đầu tiên đúng luôn\",\n",
    "    \"Sở thích của mình là lập trình các dự án hay\"\n",
    "]\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410117e",
   "metadata": {},
   "source": [
    "# tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acc1a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenizer = Tokenizer(num_words=100, oov_token=\"<OOV>\") #giới hạn từ vựng trong phạm vi 100 từ phổ biến nhất"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22a688",
   "metadata": {},
   "source": [
    "# train - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bd5fca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1,\n",
      " 'an': 27,\n",
      " 'bạn': 17,\n",
      " 'bằng': 9,\n",
      " 'chơi': 39,\n",
      " 'chạy': 44,\n",
      " 'code': 43,\n",
      " 'computer': 15,\n",
      " 'các': 54,\n",
      " 'có': 5,\n",
      " 'của': 51,\n",
      " 'dự': 10,\n",
      " 'em': 34,\n",
      " 'game': 29,\n",
      " 'giải': 8,\n",
      " 'giống': 36,\n",
      " 'gì': 41,\n",
      " 'hay': 12,\n",
      " 'huy': 23,\n",
      " 'học': 6,\n",
      " 'khoa': 20,\n",
      " 'khoá': 14,\n",
      " 'không': 7,\n",
      " 'luôn': 49,\n",
      " 'là': 53,\n",
      " 'lần': 45,\n",
      " 'lập': 2,\n",
      " 'muốn': 28,\n",
      " 'máy': 21,\n",
      " 'mê': 19,\n",
      " 'mình': 52,\n",
      " 'mỹ': 31,\n",
      " 'nhiều': 32,\n",
      " 'python': 30,\n",
      " 'quyết': 24,\n",
      " 'science': 16,\n",
      " 'scratch': 33,\n",
      " 'sở': 50,\n",
      " 'thích': 4,\n",
      " 'thấy': 35,\n",
      " 'tiên': 47,\n",
      " 'trình': 3,\n",
      " 'trò': 38,\n",
      " 'tính': 22,\n",
      " 'tôi': 13,\n",
      " 'vấn': 25,\n",
      " 'với': 37,\n",
      " 'án': 11,\n",
      " 'đam': 18,\n",
      " 'đã': 42,\n",
      " 'đúng': 48,\n",
      " 'đầu': 46,\n",
      " 'đề': 26,\n",
      " 'đố': 40}\n"
     ]
    }
   ],
   "source": [
    "# huấn luận tokenizer trên tập dữ liệu\n",
    "Tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# in ra từ điển\n",
    "word_index = Tokenizer.word_index\n",
    "pprint(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcb077d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu gốc: Tôi thích học khoá Computer Science.\n",
      "Câu sau khi token: [13, 4, 6, 14, 15, 16]\n",
      "\n",
      "Câu gốc: Bạn có đam mê khoa học máy tính không?\n",
      "Câu sau khi token: [17, 5, 18, 19, 20, 6, 21, 22, 7]\n",
      "\n",
      "Câu gốc: Huy thích lập trình giải quyết vấn đề.\n",
      "Câu sau khi token: [23, 4, 2, 3, 8, 24, 25, 26]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sử dụng tokenizer để huấn luyện tokenize câu đầu tiên\n",
    "test_sentence = sentences[0:3]\n",
    "sequences = Tokenizer.texts_to_sequences(test_sentence)\n",
    "\n",
    "# in ra kết quả\n",
    "for i,seq in enumerate(sequences):\n",
    "    print(f\"Câu gốc: {test_sentence[i]}\")\n",
    "    print(f\"Câu sau khi token: {seq}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c125e697",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cd305d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tôi thích học khoá Computer Science.',\n",
       " 'Bạn có đam mê khoa học máy tính không?',\n",
       " 'Con bò biết bay được không? có nó có thể bay được trong mơ của bạn']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = [\n",
    "    \"Tôi thích học khoá Computer Science.\",\n",
    "    \"Bạn có đam mê khoa học máy tính không?\",\n",
    "    \"Con bò biết bay được không? có nó có thể bay được trong mơ của bạn\"\n",
    "]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29d563b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu gốc: Tôi thích học khoá Computer Science.\n",
      "Câu sau khi token: [13, 4, 6, 14, 15, 16]\n",
      "\n",
      "Câu gốc: Bạn có đam mê khoa học máy tính không?\n",
      "Câu sau khi token: [17, 5, 18, 19, 20, 6, 21, 22, 7]\n",
      "\n",
      "Câu gốc: Con bò biết bay được không? có nó có thể bay được trong mơ của bạn\n",
      "Câu sau khi token: [1, 1, 1, 1, 1, 7, 5, 1, 5, 1, 1, 1, 1, 1, 51, 17]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sequences = Tokenizer.texts_to_sequences(test_data)\n",
    "for i,seq in enumerate(test_sequences):\n",
    "    print(f\"Câu gốc: {test_data[i]}\")\n",
    "    print(f\"Câu sau khi token: {seq}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a679a",
   "metadata": {},
   "source": [
    "# pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6eafb18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  4  6 14 15 16  0  0  0  0]\n",
      " [17  5 18 19 20  6 21 22  7  0]\n",
      " [23  4  2  3  8 24 25 26  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "padded_sequences = pad_sequences(sequences, maxlen=10, padding='post', truncating='post')\n",
    "print(padded_sequences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
